{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Layered Queueing Network with Cache - Three Hosts\n",
    "\n",
    "This example demonstrates a layered queueing network (LQN) with cache and backend service distributed across three hosts. The model includes cache hits that are served locally and cache misses that require backend service calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Kotlin notebook\n",
    "import jline.*\n",
    "import jline.lang.*\n",
    "import jline.lang.nodes.*\n",
    "import jline.lang.processes.*\n",
    "import jline.lang.constant.*\n",
    "import jline.lang.layered.*\n",
    "import jline.solvers.ln.*\n",
    "import jline.solvers.mva.*\n",
    "import jline.solvers.nc.*\n",
    "import jline.util.matrix.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val model = LayeredNetwork(\"LQNwithCaching\")\n",
    "val nUsers = 1\n",
    "val nTokens = 1\n",
    "\n",
    "// Client processor and task (Host 1)\n",
    "val P1 = Processor(model, \"P1\", 1, SchedStrategy.PS)\n",
    "val T1 = Task(model, \"T1\", nUsers, SchedStrategy.REF).on(P1)\n",
    "val E1 = Entry(model, \"E1\").on(T1)\n",
    "\n",
    "println(\"Client Configuration (Host 1):\")\n",
    "println(\"- Processor P1: 1 server, PS scheduling\")\n",
    "println(\"- Task T1: $nUsers users, REF scheduling\")\n",
    "println(\"- Entry E1: Client entry point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "// Cache task configuration (Host 2)\nval totalItems = 4\nval cacheCapacity = 2  // Single cache level with 2 items\n\n// Create uniform access probabilities\nval accessProbs = Matrix(1, totalItems).fill(1.0 / totalItems)\nval pAccess = DiscreteSampler(accessProbs)\n\nval PC = Processor(model, \"Pc\", 1, SchedStrategy.PS)\nval C2 = CacheTask(model, \"CT\", totalItems, cacheCapacity, ReplacementStrategy.RR, nTokens).on(PC)\nval I2 = ItemEntry(model, \"IE\", totalItems, pAccess).on(C2)\n\nprintln(\"\\nCache Configuration (Host 2):\")\nprintln(\"- Total items: $totalItems\")\nprintln(\"- Cache capacity: $cacheCapacity\")\nprintln(\"- Replacement strategy: Round Robin (RR)\")\nprintln(\"- Access pattern: Uniform (${1.0/totalItems} probability per item)\")\nprintln(\"- Processor Pc: 1 server, PS scheduling\")\nprintln(\"- Cache tokens: $nTokens\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Backend service configuration (Host 3)\n",
    "val P3 = Processor(model, \"P2\", 1, SchedStrategy.PS)\n",
    "val T3 = Task(model, \"T2\", 1, SchedStrategy.FCFS).on(P3)\n",
    "val E3 = Entry(model, \"E2\").on(T3)\n",
    "val A3 = Activity(model, \"A2\", Exp(5.0)).on(T3).boundTo(E3).repliesTo(E3)\n",
    "\n",
    "println(\"\\nBackend Service Configuration (Host 3):\")\n",
    "println(\"- Processor P2: 1 server, PS scheduling\")\n",
    "println(\"- Task T2: 1 task, FCFS scheduling\")\n",
    "println(\"- Entry E2: Backend service entry\")\n",
    "println(\"- Activity A2: Backend processing (Exp(5.0))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Define activities and cache logic\n",
    "val A1 = Activity(model, \"A1\", Immediate()).on(T1).boundTo(E1).synchCall(I2, 1)\n",
    "val AC2 = Activity(model, \"Ac\", Immediate()).on(C2).boundTo(I2)\n",
    "val AC2h = Activity(model, \"Ac_hit\", Exp(1.0)).on(C2).repliesTo(I2)  // Cache hit - local service\n",
    "val AC2m = Activity(model, \"Ac_miss\", Exp(0.5)).on(C2).synchCall(E3, 1).repliesTo(I2)  // Cache miss - backend call\n",
    "\n",
    "// Add cache access precedence\n",
    "C2.addPrecedence(ActivityPrecedence.CacheAccess(AC2, arrayOf(AC2h, AC2m)))\n",
    "\n",
    "println(\"\\nActivity Configuration:\")\n",
    "println(\"- A1: Client activity (immediate) calls cache\")\n",
    "println(\"- Ac: Cache access activity (immediate)\")\n",
    "println(\"- Ac_hit: Cache hit activity (Exp(1.0) - fast local service)\")\n",
    "println(\"- Ac_miss: Cache miss activity (Exp(0.5) + backend call)\")\n",
    "println(\"- Cache access precedence: Ac → {Ac_hit, Ac_miss}\")\n",
    "println(\"- Backend call: Ac_miss → E2 (Host 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Solve with Layered Network solver using NC\n",
    "try {\n",
    "    val lnOptions = LN.defaultOptions()\n",
    "    lnOptions.verbose = true\n",
    "    \n",
    "    val ncOptions = NC.defaultOptions()\n",
    "    ncOptions.verbose = false\n",
    "    \n",
    "    val solver1 = LN(model) { subModel -> NC(subModel, ncOptions) }\n",
    "    solver1.options = lnOptions\n",
    "    \n",
    "    val avgTable1 = solver1.avgTable\n",
    "    println(\"\\n=== Layered Network Results (NC Solver) ===\")\n",
    "    avgTable1.print()\n",
    "    \n",
    "} catch (e: Exception) {\n",
    "    println(\"\\nLN with NC failed: ${e.message}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Solve with Layered Network solver using MVA for comparison\n",
    "try {\n",
    "    val lnOptions = LN.defaultOptions()\n",
    "    lnOptions.verbose = true\n",
    "    \n",
    "    val mvaOptions = MVA.defaultOptions()\n",
    "    mvaOptions.verbose = false\n",
    "    \n",
    "    val solver2 = LN(model) { subModel -> MVA(subModel, mvaOptions) }\n",
    "    solver2.options = lnOptions\n",
    "    \n",
    "    val avgTable2 = solver2.avgTable\n",
    "    println(\"\\n=== Layered Network Results (MVA Solver) ===\")\n",
    "    avgTable2.print()\n",
    "    \n",
    "} catch (e: Exception) {\n",
    "    println(\"\\nLN with MVA failed: ${e.message}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Analyze the three-host distributed cache system\n",
    "println(\"\\n=== Three-Host Distributed Cache Analysis ===\")\n",
    "println(\"This model demonstrates a distributed architecture:\")\n",
    "println(\"\\n1. Three-Tier Architecture:\")\n",
    "println(\"   - Host 1: Client tier (users generate requests)\")\n",
    "println(\"   - Host 2: Cache tier (intermediate caching layer)\")\n",
    "println(\"   - Host 3: Backend tier (authoritative data source)\")\n",
    "println(\"\\n2. Cache Behavior:\")\n",
    "println(\"   - Cache hits: Served locally on Host 2 (fast)\")\n",
    "println(\"   - Cache misses: Require call to Host 3 (slower)\")\n",
    "println(\"   - Hit ratio ≈ $cacheCapacity/$totalItems = ${cacheCapacity.toDouble()/totalItems}\")\n",
    "println(\"\\n3. Performance Characteristics:\")\n",
    "println(\"   - Hit latency: Exp(1.0) local processing\")\n",
    "println(\"   - Miss latency: Exp(0.5) cache processing + Exp(5.0) backend\")\n",
    "println(\"   - Backend is significantly slower (5.0 vs 1.0 rate)\")\n",
    "println(\"   - Network delays between hosts (implicit in LQN)\")\n",
    "println(\"\\n4. Traffic Flow:\")\n",
    "println(\"   - Client → Cache (always)\")\n",
    "println(\"   - Cache → Backend (only on misses)\")\n",
    "println(\"   - Response path: Backend → Cache → Client\")\n",
    "println(\"\\n5. Scalability Implications:\")\n",
    "println(\"   - Cache reduces backend load by factor of hit ratio\")\n",
    "println(\"   - Backend load = arrival rate × miss ratio\")\n",
    "println(\"   - Cache effectiveness critical for system performance\")\n",
    "println(\"\\nReal-world Applications:\")\n",
    "println(\"- Web application with Redis cache and database\")\n",
    "println(\"- CDN with origin server\")\n",
    "println(\"- Microservices with caching layer\")\n",
    "println(\"- Distributed database with cache nodes\")\n",
    "println(\"\\nPerformance Tuning Insights:\")\n",
    "val hitRatio = cacheCapacity.toDouble() / totalItems\n",
    "val missRatio = 1.0 - hitRatio\n",
    "println(\"- Expected backend load reduction: ${(hitRatio * 100).toInt()}%\")\n",
    "println(\"- Cache miss penalty: ~6x slower (0.5 + 5.0 vs 1.0)\")\n",
    "println(\"- Increasing cache capacity from $cacheCapacity to ${cacheCapacity+1} would improve hit ratio to ${(cacheCapacity+1).toDouble()/totalItems}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "This example demonstrates:\n",
    "\n",
    "1. **Distributed Layered Architecture**: \n",
    "   - Three-tier system with client, cache, and backend layers\n",
    "   - Inter-host communication via synchronous calls\n",
    "   - Network effects implicit in LQN modeling\n",
    "2. **Cache-Backend Integration**:\n",
    "   - Cache hits served locally (fast response)\n",
    "   - Cache misses trigger backend calls (slower response)\n",
    "   - Cache acts as performance multiplier for backend\n",
    "3. **Performance Differentiation**:\n",
    "   - Local cache processing: Exp(1.0)\n",
    "   - Cache miss processing: Exp(0.5) + backend call\n",
    "   - Backend processing: Exp(5.0) (much slower)\n",
    "4. **Solver Comparison**:\n",
    "   - NC (Normalizing Constant) vs MVA solvers\n",
    "   - Different numerical approaches for same model\n",
    "   - Validation of solution consistency\n",
    "5. **Scalability Analysis**:\n",
    "   - Cache reduces backend load proportional to hit ratio\n",
    "   - Backend becomes bottleneck when cache ineffective\n",
    "   - System performance highly sensitive to cache sizing\n",
    "\n",
    "This model is essential for:\n",
    "- Distributed system design\n",
    "- Cache sizing decisions\n",
    "- Backend capacity planning\n",
    "- Understanding cache effectiveness in reducing system load\n",
    "- Analyzing multi-tier application performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}