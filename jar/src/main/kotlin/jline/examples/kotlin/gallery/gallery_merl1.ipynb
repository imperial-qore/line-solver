{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Gallery Example: M/E\u2082/1 Queue (Erlang Service)\n",
        "\n",
        "This example demonstrates an M/E\u2082/1 queueing system:\n",
        "- **Arrivals**: Poisson process (Exponential inter-arrival times)\n",
        "- **Service**: Erlang-2 service times (less variable than exponential)\n",
        "- **Servers**: 1 server\n",
        "- **Capacity**: Infinite\n",
        "- **Scheduling**: FCFS\n",
        "\n",
        "The Erlang-2 service distribution has lower variance than exponential, representing more consistent service times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Kotlin notebook\nimport jline.*\nimport jline.lang.*\nimport jline.lang.nodes.*\nimport jline.lang.processes.*\nimport jline.lang.constant.*\nimport jline.solvers.ctmc.*\nimport jline.solvers.fluid.*\nimport jline.solvers.mva.*\nGlobalConstants.setVerbose(VerboseLevel.STD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "fun gallery_merl1(): Network {    \"\"\"Create M/E\u2082/1 queueing model\"\"\"    model = Network(\"M/E/1\")        # Block 1: nodes    source = Source(model, \"mySource\")    queue = Queue(model, \"myQueue\", SchedStrategy.FCFS)    sink = Sink(model, \"mySink\")        # Block 2: classes    oclass = OpenClass(model, \"myClass\")    # Exponential arrivals with rate \u03bb=1    source.setArrival(oclass, Exp(1))    # Erlang-2 service with mean=0.5 and order=2    queue.setService(oclass, Erlang.fit_mean_and_order(0.5, 2))        # Block 3: topology    P = model.initRoutingMatrix()    P.addRoute(oclass, source, queue, 1.0)    P.addRoute(oclass, queue, sink, 1.0)    model.link(P)        return model, source, queue, sink, oclass# Create the modelmodel, source, queue, sink, oclass = gallery_merl1()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## Theoretical Analysis for M/E\u2082/1\n",
        "\n",
        "For M/E\u2082/1 with:\n",
        "- **Arrival rate**: \u03bb = 1 (Exponential with mean=1)\n",
        "- **Service time**: Erlang-2 with mean=0.5, order=2\n",
        "- **Utilization**: \u03c1 = \u03bb \u00d7 E[S] = 1 \u00d7 0.5 = 0.5\n",
        "\n",
        "The Erlang-2 service distribution characteristics:\n",
        "- **Mean**: 0.5\n",
        "- **Variance**: (0.5)\u00b2/2 = 0.125 (lower than exponential variance = 0.25)\n",
        "- **Coefficient of Variation**: C\u00b2\u209b = 1/2 = 0.5\n",
        "\n",
        "Lower service variability typically leads to better performance than M/M/1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Solve with multiple solvers\nprintln(\"\\n=== Solver Results ===\")\n// MVA Solver\nval solver_mva = MVA(model)\nval avg_table_mva = solver_mva.avgTable\nprintln(\"\\nMVA Solver:\")\nprintln(avg_table_mva)\n// CTMC Solver\nval solver_ctmc = CTMC(model, \"cutoff\", 15)\nval avg_table_ctmc = solver_ctmc.avgTable\nprintln(\"\\nCTMC Solver:\")\nprintln(avg_table_ctmc)\n// Fluid Solver\nval solver_fluid = FLD(model)\nval avg_table_fluid = solver_fluid.avgTable\nprintln(\"\\nFluid Solver:\")\nprintln(avg_table_fluid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Compare M/E\u2082/1 with M/M/1\nprintln(\"\\n=== Comparison with M/M/1 ===\")\n// Create equivalent M/M/1 model\nfun create_mm1_equivalent(): Network {\n    val model_mm1 = Network(\"M/M/1-Equivalent\")\n    val source = Source(model_mm1, \"Source\")\n    val queue = Queue(model_mm1, \"Queue\", SchedStrategy.FCFS)\n    val sink = Sink(model_mm1, \"Sink\")\n    \n    val oclass = OpenClass(model_mm1, \"Class\")\n    source.setArrival(oclass, Exp(1))  # Same arrival rate\n    queue.setService(oclass, Exp(2))   # Exponential with mean = 0.5\n    \n    val P = model_mm1.initRoutingMatrix()\n    P.addRoute(oclass, source, queue, 1.0)\n    P.addRoute(oclass, queue, sink, 1.0)\n    model_mm1.link(P)\n    \n    return model_mm1\n\nval model_mm1 = create_mm1_equivalent()\nval solver_merl = MVA(model)\nval solver_mm1 = MVA(model_mm1)\n\nval avg_table_merl = solver_merl.avgTable\nval avg_table_mm1 = solver_mm1.avgTable\n\nprintln(\"M/E\u2082/1 Results:\")\nprintln(avg_table_merl)\n\nprintln(\"\\nM/M/1 Results:\")\nprintln(avg_table_mm1)\n// Extract key metrics for comparison\nval merl_resp = float(avg_table_merl.iloc[1, 2])  # Queue response time\nval merl_length = float(avg_table_merl.iloc[1, 3])  # Queue length\n\nval mm1_resp = float(avg_table_mm1.iloc[1, 2])  # Queue response time\nval mm1_length = float(avg_table_mm1.iloc[1, 3])  # Queue length\n\nprintln(f\"\\nPerformance Comparison:\")\nprintln(f\"Response Time: M/E\u2082/1={merl_resp:.4f}, M/M/1={mm1_resp:.4f}\")\nprintln(f\"Queue Length: M/E\u2082/1={merl_length:.4f}, M/M/1={mm1_length:.4f}\")\nval improvement = ((mm1_resp - merl_resp) / mm1_resp * 100) if mm1_resp > merl_resp else ((merl_resp - mm1_resp) / mm1_resp * 100)\nprintln(f\"Improvement: {improvement:.1f}% {\"better\" if mm1_resp > merl_resp else \"worse\"} response time with Erlang service\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Analyze impact of Erlang order for service times\nprintln(\"\\n=== Impact of Service Time Variability ===\")\n\nfun create_service_erlang_model(order): Network {\n    \"\"\"Create M/E\u2096/1 model with specified Erlang order for service\"\"\"\n    val model_erl = Network(f\"M/E{order}/1\")\n    val source = Source(model_erl, \"Source\")\n    val queue = Queue(model_erl, \"Queue\", SchedStrategy.FCFS)\n    val sink = Sink(model_erl, \"Sink\")\n    \n    val oclass = OpenClass(model_erl, \"Class\")\n    source.setArrival(oclass, Exp(1))\n    queue.setService(oclass, Erlang.fit_mean_and_order(0.5, order))\n    \n    val P = model_erl.initRoutingMatrix()\n    P.addRoute(oclass, source, queue, 1.0)\n    P.addRoute(oclass, queue, sink, 1.0)\n    model_erl.link(P)\n    \n    return model_erl\n// Test different Erlang orders for service\nval orders = [1, 2, 3, 5, 10]  # Order 1 = Exponential\n\nprintln(\"Service Order | C\u00b2\u209b  | Response Time | Queue Length\")\nprintln(\"-\" * 50)\n\nfor order in orders:\n    val model_order = create_service_erlang_model(order)\n    val solver = MVA(model_order)\n    val avg_table = solver.avgTable\n    \n    val resp_time = float(avg_table.iloc[1, 2])\n    val queue_length = float(avg_table.iloc[1, 3])\n    val cv_squared = 1.0 / order  # Coefficient of variation squared for Erlang\n    \n    println(f\"     {order:2d}       | {cv_squared:.3f} |     {resp_time:.4f}    |    {queue_length:.4f}\")\n\nprintln(\"\\nNote: Higher order (lower C\u00b2\u209b) leads to better performance due to reduced service variability.\")\nprintln(\"As order\u2192\u221e, the system approaches M/D/1 (deterministic service).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Compare with M/H\u2082/1 (hyperexponential service)\nprintln(\"\\n=== Comparison: Low vs High Service Variability ===\")\n\nfun create_mhyp1_model(): Network {\n    \"\"\"Create M/H\u2082/1 model with hyperexponential service\"\"\"\n    val model_hyp = Network(\"M/H2/1\")\n    val source = Source(model_hyp, \"Source\")\n    val queue = Queue(model_hyp, \"Queue\", SchedStrategy.FCFS)\n    val sink = Sink(model_hyp, \"Sink\")\n    \n    val oclass = OpenClass(model_hyp, \"Class\")\n    source.setArrival(oclass, Exp(1))\n    queue.setService(oclass, HyperExp.fit_mean_and_scv(0.5, 4))  # High variability\n    \n    val P = model_hyp.initRoutingMatrix()\n    P.addRoute(oclass, source, queue, 1.0)\n    P.addRoute(oclass, queue, sink, 1.0)\n    model_hyp.link(P)\n    \n    return model_hyp\n\nval model_hyp = create_mhyp1_model()\nval model_erl = create_service_erlang_model(5)  # Low variability\n\nval solver_hyp = MVA(model_hyp)\nval solver_erl = MVA(model_erl)\n\nval avg_table_hyp = solver_hyp.avgTable\nval avg_table_erl = solver_erl.avgTable\n\nval hyp_resp = float(avg_table_hyp.iloc[1, 2])\nval erl_resp = float(avg_table_erl.iloc[1, 2])\n\nprintln(f\"Service Distribution | C\u00b2\u209b | Response Time\")\nprintln(\"-\" * 40)\nprintln(f\"Erlang-5 (low var)   | 0.2 |    {erl_resp:.4f}\")\nprintln(f\"Exponential          | 1.0 |    {mm1_resp:.4f}\")\nprintln(f\"Hyperexp (high var)  | 4.0 |    {hyp_resp:.4f}\")\n\nprintln(f\"\\nVariability Impact: {(hyp_resp / erl_resp):.1f}x difference between high and low service variability\")\nprintln(\"This demonstrates the fundamental principle: variability degrades queueing performance.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Kotlin",
      "language": "kotlin",
      "name": "kotlin"
    },
    "language_info": {
      "name": "kotlin",
      "version": "1.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}