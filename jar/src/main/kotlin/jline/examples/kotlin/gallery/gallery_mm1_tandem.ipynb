{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Gallery Example: M/M/1 Tandem Network\n",
        "\n",
        "This example demonstrates a simple tandem network of two M/M/1 queues in series:\n",
        "- **Topology**: 2 queues in series (tandem)\n",
        "- **Arrivals**: Poisson process to first queue\n",
        "- **Service**: Exponential service times at both stations\n",
        "- **Servers**: 1 server at each station\n",
        "- **Scheduling**: FCFS at both stations\n",
        "\n",
        "This is a fundamental network topology used to model sequential processing stages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Kotlin notebook\nimport jline.*\nimport jline.lang.*\nimport jline.lang.nodes.*\nimport jline.lang.processes.*\nimport jline.lang.constant.*\nimport jline.solvers.ctmc.*\nimport jline.solvers.fluid.*\nimport jline.solvers.mva.*\nGlobalConstants.setVerbose(VerboseLevel.STD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "fun gallery_mm1_tandem(): Network {    \"\"\"Create simple M/M/1 tandem network (2 queues in series)\"\"\"    # Use the linear model with n=2 and default utilization pattern    from gallery_mm1_linear import gallery_mm1_linear  # Import would work in practice        # Alternative: create directly for better control    model = Network(\"M/M/1-Tandem\")        # Block 1: nodes    source = Source(model, \"mySource\")    queue1 = Queue(model, \"Queue1\", SchedStrategy.FCFS)    queue2 = Queue(model, \"Queue2\", SchedStrategy.FCFS)    sink = Sink(model, \"mySink\")        # Block 2: classes    oclass = OpenClass(model, \"myClass\")    source.setArrival(oclass, Exp(1))  # \u03bb = 1        # Symmetric utilization: both stations have similar load    queue1.setService(oclass, Exp.fitMean(0.4))  # Service time = 0.4, so \u03c1\u2081 = 0.4    queue2.setService(oclass, Exp.fitMean(0.3))  # Service time = 0.3, so \u03c1\u2082 = 0.3        # Block 3: topology - serial routing    P = model.initRoutingMatrix()    P.addRoute(oclass, source, queue1, 1.0)    P.addRoute(oclass, queue1, queue2, 1.0)    P.addRoute(oclass, queue2, sink, 1.0)    model.link(P)        return model# Create the modelmodel = gallery_mm1_tandem()println(f\"Topology: Source -> Queue1 -> Queue2 -> Sink\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## Theoretical Analysis for Tandem Network\n",
        "\n",
        "For a tandem network with arrival rate \u03bb and service times s\u2081, s\u2082:\n",
        "- **Throughput**: Same at all stations (\u03bb = 1)\n",
        "- **Utilization**: \u03c1\u1d62 = \u03bb \u00d7 s\u1d62\n",
        "  - \u03c1\u2081 = 1 \u00d7 0.4 = 0.4\n",
        "  - \u03c1\u2082 = 1 \u00d7 0.3 = 0.3\n",
        "- **Response Time**: W_total = W\u2081 + W\u2082\n",
        "- **Queue Length**: L_total = L\u2081 + L\u2082\n",
        "\n",
        "Since queues are independent (product-form network):\n",
        "- W\u2081 = s\u2081/(1-\u03c1\u2081) = 0.4/(1-0.4) = 0.667\n",
        "- W\u2082 = s\u2082/(1-\u03c1\u2082) = 0.3/(1-0.3) = 0.429\n",
        "- W_total = 0.667 + 0.429 = 1.096"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Solve with multiple solvers\nprintln(\"\\n=== Solver Results ===\")\n// MVA Solver\nval solver_mva = MVA(model)\nval avg_table_mva = solver_mva.avgTable\nprintln(\"\\nMVA Solver:\")\nprintln(avg_table_mva)\n// CTMC Solver\nval solver_ctmc = CTMC(model, \"cutoff\", 10)\nval avg_table_ctmc = solver_ctmc.avgTable\nprintln(\"\\nCTMC Solver:\")\nprintln(avg_table_ctmc)\n// Fluid Solver\nval solver_fluid = FLD(model)\nval avg_table_fluid = solver_fluid.avgTable\nprintln(\"\\nFluid Solver:\")\nprintln(avg_table_fluid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Verify theoretical predictions\nprintln(\"\\n=== Theoretical vs Simulation ===\")\n\nval solver = MVA(model)\nval avg_table = solver.avgTable\n// Extract results for Queue1 and Queue2 (skip source and sink)\nval queue1_util = float(avg_table.iloc[1, 1])  # Queue1 utilization\nval queue1_resp = float(avg_table.iloc[1, 2])  # Queue1 response time\nval queue1_length = float(avg_table.iloc[1, 3])  # Queue1 queue length\n\nval queue2_util = float(avg_table.iloc[2, 1])  # Queue2 utilization\nval queue2_resp = float(avg_table.iloc[2, 2])  # Queue2 response time\nval queue2_length = float(avg_table.iloc[2, 3])  # Queue2 queue length\n// Theoretical values\nval rho1_theory = 0.4\nval rho2_theory = 0.3\nval w1_theory = 0.4 / (1 - 0.4)\nval w2_theory = 0.3 / (1 - 0.3)\nval w_total_theory = w1_theory + w2_theory\n\nprintln(f\"Queue 1:\")\nprintln(f\"  Utilization: Theory={rho1_theory:.3f}, Simulation={queue1_util:.3f}\")\nprintln(f\"  Response Time: Theory={w1_theory:.3f}, Simulation={queue1_resp:.3f}\")\n\nprintln(f\"\\nQueue 2:\")\nprintln(f\"  Utilization: Theory={rho2_theory:.3f}, Simulation={queue2_util:.3f}\")\nprintln(f\"  Response Time: Theory={w2_theory:.3f}, Simulation={queue2_resp:.3f}\")\n\nprintln(f\"\\nTotal Response Time: Theory={w_total_theory:.3f}, Simulation={queue1_resp + queue2_resp:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "// Analyze bottleneck effects\nprintln(\"\\n=== Bottleneck Analysis ===\")\n\nfun create_tandem_with_bottleneck(bottleneck_position, service_times): Network {\n    \"\"\"Create tandem network with specified bottleneck\"\"\"\n    val model_bn = Network(f\"Tandem-Bottleneck{bottleneck_position}\")\n    val source = Source(model_bn, \"Source\")\n    val queue1 = Queue(model_bn, \"Queue1\", SchedStrategy.FCFS)\n    val queue2 = Queue(model_bn, \"Queue2\", SchedStrategy.FCFS)\n    val sink = Sink(model_bn, \"Sink\")\n    \n    val oclass = OpenClass(model_bn, \"Class\")\n    source.setArrival(oclass, Exp(1))\n    queue1.setService(oclass, Exp.fitMean(service_times[0]))\n    queue2.setService(oclass, Exp.fitMean(service_times[1]))\n    \n    val P = model_bn.initRoutingMatrix()\n    P.addRoute(oclass, source, queue1, 1.0)\n    P.addRoute(oclass, queue1, queue2, 1.0)\n    P.addRoute(oclass, queue2, sink, 1.0)\n    model_bn.link(P)\n    \n    return model_bn\n// Test different bottleneck scenarios\nval scenarios = [\n    (\"Balanced\", [0.3, 0.3]),\n    (\"Queue1 Bottleneck\", [0.8, 0.2]),\n    (\"Queue2 Bottleneck\", [0.2, 0.8])\n]\n\nfor name, service_times in scenarios:\n    val model_scenario = create_tandem_with_bottleneck(1 if service_times[0] > service_times[1] else 2, service_times)\n    val solver = MVA(model_scenario)\n    val avg_table = solver.avgTable\n    \n    val q1_util = float(avg_table.iloc[1, 1])\n    val q2_util = float(avg_table.iloc[2, 1])\n    val total_resp = float(avg_table.iloc[1, 2]) + float(avg_table.iloc[2, 2])\n    \n    println(f\"{name}: \u03c1\u2081={q1_util:.3f}, \u03c1\u2082={q2_util:.3f}, W_total={total_resp:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Kotlin",
      "language": "kotlin",
      "name": "kotlin"
    },
    "language_info": {
      "name": "kotlin",
      "version": "1.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}